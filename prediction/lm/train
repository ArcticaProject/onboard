#!/usr/bin/env python
# -*- coding: latin-1 -*-

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# Author: marmuta <marmvta@gmail.com>
#

import sys,math
import codecs
import re
import lm

from contextlib import contextmanager

@contextmanager
def timeit(s):
    import time, gc
    gc.collect()
    gc.collect()
    gc.collect()
    t = time.time()
    yield None
    print "time: %fms%s" % ((time.time() - t)*1000, " for "+s if s else "")


def main():
    global model # for debugging

    model = LanguageModel()
    training, held_out, testing = model.read_corpus(sys.argv[1])

    model.set_order(int(sys.argv[2]))

    with timeit("training"):
        model.train(training)
        model.train(held_out)   # abuse held_out for now
        model.train(testing)    # abuse testing for now

    model.info()

    with timeit("save"):
        model.save(sys.argv[3])

class LanguageModel(lm.LanguageModelDynamic):

    def read_corpus(self, filename):
        # read corpus
        #s = codecs.open(filename, encoding='utf-8').read() \
        s = codecs.open(filename, encoding='latin-1').read() \
            .replace("\r"," ") # remove carriage returns from Moby Dick

        # split into sentences including separaters (punctuation, newlines)
        sentences = re.findall(""".*?(?:[\.;:!?][\s\"]  # punctuation
                                      | \s*\\n\s*\\n)   # double newline
                               """, s, re.UNICODE|re.DOTALL|re.VERBOSE)
        # divide corpus into 3 sections: training, held_out, test
        r = range(len(sentences))
        sh = set(r[5::20])
        st = set(r[15::20])
        training  = [sentences[i] for i in set(r) - sh - st]
        held_out  = [sentences[i] for i in sh]
        testing   = [sentences[i] for i in st]
        print "sentences: total %d, training %d, held_out %d, testing %d" % \
              (len(sentences),len(training),len(held_out),len(testing))

        return training, held_out, testing


    def info(self):
        counts = [0]*self.order
        totals = [0]*self.order
        for ng in self.iter_ngrams():
            counts[len(ng[0])-1] +=  1
            totals[len(ng[0])-1] += ng[1]

        for i,c in enumerate(counts):
            print "%d-grams: count %d, total %d" % \
                  (i+1, counts[i], totals[i])


    def train(self, sentences):
        """ extract and count n-grams """
        for sentence in sentences:
            words = self.split_sentence(sentence)
            for i,word in enumerate(words):
                for n in xrange(self.order):
                    if i+n+1 <= len(words):
                        assert(n == len(words[i:i+n+1])-1)
                        self.count_ngram(words[i:i+n+1])

    def train(self, sentences):
        """ extract and count n-grams """
        words = []
        for sentence in sentences:
            words += self.split_sentence(sentence)[:-1]

        for i,word in enumerate(words):
            for n in xrange(self.order):
                if i+n+1 <= len(words):
                    assert(n == len(words[i:i+n+1])-1)
                    self.count_ngram(words[i:i+n+1])

    def split_sentence(self, sentence):
        words = re.findall(u"[^\W\d]\w*(?:[-'][\w]+)*",
                           sentence, re.UNICODE|re.VERBOSE)
        if words:
            words = [u"<s>"] + words + [u"<\s>"]
        return words


if __name__ == '__main__':
    main()

